import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np
import os
import argparse
import torchvision
import torchvision.transforms as transforms
from collections import OrderedDict
from resnet import resnet20 # ç¡®ä¿å¯ä»¥ä» resnet.py å¯¼å…¥ resnet20 æ¨¡å‹
import math

def get_relu_input_distributions_per_channel(pth_file_path, batch_size, data_dir, save_dir):
    """
    è·å–å¹¶å¯è§†åŒ–æ‰€æœ‰ ReLU å±‚çš„è¾“å…¥æ•°æ®åˆ†å¸ƒï¼Œæ¯å±‚ä¸€å¼ å¤§å›¾ï¼ŒæŒ‰é€šé“åˆ’åˆ†å¤šä¸ªå­å›¾ã€‚
    """
    # 1. åŠ è½½æ¨¡å‹
    model = resnet20()
    try:
        checkpoint = torch.load(pth_file_path, map_location=torch.device('cpu'))
        state_dict = checkpoint.get('net', checkpoint)
        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        model.load_state_dict(new_state_dict)
        print(f"âœ¨ æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡ï¼š{pth_file_path}")
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹æƒé‡å¤±è´¥ï¼š{e}")
        print("è¯·ç¡®ä¿ä½ çš„ .pth æ–‡ä»¶ä¸ ResNet20 æ¨¡å‹ç»“æ„åŒ¹é…ã€‚")
        return

    model.eval()

    # 2. æ³¨å†Œ Hook æ¥æ•è·æ‰€æœ‰ ReLU å±‚çš„è¾“å…¥
    relu_input_data = OrderedDict()
    
    for name, module in model.named_modules():
        if isinstance(module, nn.ReLU):
            relu_input_data[name] = []
            
            def hook_fn(module, input, name=name):
                relu_input_data[name].append(input[0].detach().cpu())

            module.register_forward_pre_hook(hook_fn)
            print(f"ğŸ’¡ å·²ä¸º ReLU å±‚ '{name}' æ³¨å†Œè¾“å…¥æ•è· Hookã€‚")

    if not relu_input_data:
        print("âŒ æœªåœ¨æ¨¡å‹ä¸­æ‰¾åˆ°ä»»ä½• nn.ReLU å±‚ã€‚è¯·æ£€æŸ¥æ¨¡å‹ç»“æ„ã€‚")
        return

    # 3. åŠ è½½ CIFAR-10 è®­ç»ƒæ•°æ®é›† (ä¿®æ”¹éƒ¨åˆ†)
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ])
    # å°† train=False ä¿®æ”¹ä¸º train=True
    trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=2)

    print(f"ğŸš€ å¼€å§‹ä½¿ç”¨ CIFAR-10 è®­ç»ƒæ•°æ®é›†è¿›è¡Œå‰å‘ä¼ æ’­ä»¥æ•è·æ‰€æœ‰ ReLU å±‚è¾“å…¥...")
    with torch.no_grad():
        # å°† testloader æ›¿æ¢ä¸º trainloader
        for i, (inputs, labels) in enumerate(trainloader):
            _ = model(inputs)
            if (i + 1) % 100 == 0:
                print(f"  Processed {i + 1}/{len(trainloader)} batches.")

    print("âœ… å‰å‘ä¼ æ’­å®Œæˆï¼Œæ‰€æœ‰ ReLU å±‚çš„è¾“å…¥æ•°æ®å·²æ•è·ã€‚")

    # 4. åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    images_dir = os.path.join(save_dir, 'distributions_per_channel')
    os.makedirs(images_dir, exist_ok=True)
    txt_path = os.path.join(save_dir, 'relu_input_ranges.txt')

    # 5. å¯è§†åŒ–å¹¶ä¿å­˜ç»“æœ
    with open(txt_path, 'w') as f_txt:
        f_txt.write("ReLU Layer Input Ranges\n")
        f_txt.write("=======================\n\n")

        for name, data_list in relu_input_data.items():
            if not data_list:
                print(f"âš ï¸ è­¦å‘Šï¼šæœªæ•è·åˆ° '{name}' å±‚çš„è¾“å…¥æ•°æ®ï¼Œè·³è¿‡ã€‚")
                continue

            # å°†æ‰€æœ‰æ‰¹æ¬¡çš„è¾“å…¥æ•°æ®è¿æ¥èµ·æ¥
            all_inputs = torch.cat(data_list, dim=0)
            
            # è·å–æ•°æ®ç»´åº¦ï¼š[batch_size, channels, height, width]
            num_channels = all_inputs.shape[1]
            
            # --- å†™å…¥ txt æ–‡ä»¶ ---
            global_min = all_inputs.min().item()
            global_max = all_inputs.max().item()
            f_txt.write(f"Layer Name: {name}\n")
            f_txt.write(f"  Global Input Range: [{global_min:.6f}, {global_max:.6f}]\n")
            f_txt.write("  Per-Channel Input Ranges:\n")
            for c in range(num_channels):
                channel_data = all_inputs[:, c, :, :].numpy().flatten()
                channel_min = np.min(channel_data)
                channel_max = np.max(channel_data)
                f_txt.write(f"    Channel {c}: [{channel_min:.6f}, {channel_max:.6f}]\n")
            f_txt.write("\n")
            
            # --- å¯è§†åŒ–ï¼šæ¯ä¸ªé€šé“ä¸€ä¸ªå­å›¾ ---
            cols = int(np.ceil(np.sqrt(num_channels)))
            rows = int(np.ceil(num_channels / cols))

            x_min_all = global_min - abs(global_min * 0.1)
            x_max_all = global_max + abs(global_max * 0.1)
            
            fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 3 * rows))
            axes = axes.flatten()

            for c in range(num_channels):
                ax = axes[c]
                channel_data = all_inputs[:, c, :, :].numpy().flatten()
                ax.hist(channel_data, bins=100, color='blue', alpha=0.7)
                ax.set_title(f'Channel {c}', fontsize=8)
                ax.set_yscale('log')
                ax.tick_params(axis='both', which='major', labelsize=6)
                ax.grid(True, linestyle='--', alpha=0.6)
                ax.set_xlim(x_min_all, x_max_all)

            for i in range(num_channels, len(axes)):
                fig.delaxes(axes[i])
            
            plt.suptitle(f'ReLU Input Distribution for Layer: {name} (Total Channels: {num_channels})', fontsize=12)
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])

            save_filename = os.path.join(images_dir, f'relu_input_distribution_{name.replace(".", "_")}.png')
            plt.savefig(save_filename, dpi=200)
            plt.close()
            print(f"ğŸ–¼ï¸ '{name}' å±‚çš„åˆ†é€šé“è¾“å…¥åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ° {save_filename}")
    
    print(f"\nğŸ’¾ æ‰€æœ‰ ReLU å±‚çš„è¾“å…¥èŒƒå›´ä¿¡æ¯å·²ä¿å­˜åˆ° {txt_path}")
    print("\n--- è„šæœ¬æ‰§è¡Œå®Œæ¯• ---")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Analyze and visualize the input distributions of all ReLU layers in a ResNet20 model.')
    parser.add_argument('--pth_file_path', type=str, 
                        default="/home/wangtianyu/relu_finetune/base_models/20_ckpt_92.23.pth",
                        help='Path to the .pth model file.')
    parser.add_argument('--batch_size', type=int, default=512,
                        help='Batch size for data loading.')
    parser.add_argument('--data_dir', type=str, default="./data",
                        help='Directory to store CIFAR-10 dataset.')
    parser.add_argument('--save_dir', type=str, 
                        default="/home/wangtianyu/relu_finetune/hook/relu_distributions_per_channel_trainset", # å»ºè®®ä¿®æ”¹ä¿å­˜ç›®å½•ä»¥åŒºåˆ†
                        help='Directory to save the distribution plots and text files.')
    
    args = parser.parse_args()

    get_relu_input_distributions_per_channel(args.pth_file_path, args.batch_size, args.data_dir, args.save_dir)