import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import numpy as np
import os
import argparse
import json
from collections import OrderedDict
from scipy.optimize import minimize
import torchvision
import torchvision.transforms as transforms
from resnet import resnet20 # ç¡®ä¿ä½ å¯ä»¥ä» resnet.py å¯¼å…¥ resnet20 æ¨¡å‹

# --- (ä»¥ä¸‹æ˜¯è·å– ReLU è¾“å…¥æ•°æ®çš„å‡½æ•°ï¼Œä¿®æ”¹ä»¥è¿”å›åŸå§‹ tensor å’Œå±•å¹³æ•°æ®) ---
def get_relu_input_data_for_layer(model, relu_layer_name, batch_size, data_dir):
    """
    è·å–æŒ‡å®š ReLU å±‚çš„è¾“å…¥æ•°æ®ã€‚
    è¿”å›å±•å¹³çš„ NumPy æ•°ç»„ï¼ˆç”¨äºæ‹Ÿåˆï¼‰å’ŒåŸå§‹çš„ PyTorch Tensor åˆ—è¡¨ï¼ˆç”¨äºé€šé“åˆ†å¸ƒï¼‰ã€‚
    """
    relu_input_data_list = []

    found_relu = False
    # æ³¨å†Œ forward_pre_hook æ¥æ•è· ReLU å±‚çš„è¾“å…¥
    for name, module in model.named_modules():
        if isinstance(module, nn.ReLU) and name == relu_layer_name:
            def hook_fn(module, input):
                relu_input_data_list.append(input[0].detach().cpu())
            module.register_forward_pre_hook(hook_fn)
            found_relu = True
            # print(f"ğŸ’¡ å·²ä¸º ReLU å±‚ '{relu_layer_name}' æ³¨å†Œè¾“å…¥æ•è· Hookã€‚")
            break
    
    if not found_relu:
        print(f"âŒ æœªåœ¨æ¨¡å‹ä¸­æ‰¾åˆ°æŒ‡å®šçš„ ReLU å±‚ '{relu_layer_name}'ã€‚")
        return None, None

    # åŠ è½½ CIFAR-10 æµ‹è¯•æ•°æ®é›†
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ])
    testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)
    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)

    # print(f"ğŸš€ å¼€å§‹ä½¿ç”¨ CIFAR-10 æ•°æ®é›†è¿›è¡Œå‰å‘ä¼ æ’­ä»¥æ•è· '{relu_layer_name}' è¾“å…¥...")
    with torch.no_grad():
        for i, (inputs, labels) in enumerate(testloader):
            _ = model(inputs)
            # if (i + 1) % 100 == 0:
            #     print(f"  Processed {i + 1}/{len(testloader)} batches.")
            # ä¸ºé¿å…å†…å­˜é—®é¢˜ï¼Œå¯ä»¥é™åˆ¶å¤„ç†çš„æ‰¹æ¬¡æ•°é‡
            # if i >= 10: break

    if not relu_input_data_list:
        print(f"âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰æ•è·åˆ° '{relu_layer_name}' å±‚çš„è¾“å…¥ã€‚")
        return None, None

    # å°†æ‰€æœ‰æ‰¹æ¬¡çš„ ReLU è¾“å…¥è¿æ¥èµ·æ¥
    all_relu_inputs_tensor = torch.cat(relu_input_data_list, dim=0) # åŸå§‹å½¢çŠ¶ (N, C, H, W)
    all_relu_inputs_flat = all_relu_inputs_tensor.numpy().flatten() # å±•å¹³ä¸ºä¸€ç»´æ•°ç»„ç”¨äºæ‹Ÿåˆ

    return all_relu_inputs_flat, all_relu_inputs_tensor

def relu_true(x):
    """æ ‡å‡†çš„ ReLU æ¿€æ´»å‡½æ•°"""
    return np.maximum(0, x)

def poly_eval(x, coeffs):
    """
    ä½¿ç”¨ Horner æ³•åˆ™è®¡ç®—å¤šé¡¹å¼å€¼ã€‚
    coeffs: ä»æœ€é«˜æ¬¡å¹‚åˆ°æœ€ä½æ¬¡å¹‚çš„ç³»æ•°åˆ—è¡¨æˆ– NumPy æ•°ç»„ [c_n, c_{n-1}, ..., c_0]
    """
    if len(coeffs) == 0:
        return np.zeros_like(x)
    
    result = coeffs[0] * x
    for i in range(1, len(coeffs) - 1):
        result = result + coeffs[i]
        result = result * x
    result = result + coeffs[-1]
    return result

def f1_f2_composite(x, coeffs_f1, coeffs_f2):
    """
    è®¡ç®—å¤åˆå‡½æ•° f1(f2(x)) çš„å€¼ã€‚
    """
    y_intermediate = poly_eval(x, coeffs_f2)
    return poly_eval(y_intermediate, coeffs_f1)

def objective_function(packed_coeffs, x_sample, y_true, deg1, deg2):
    """
    ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼šè®¡ç®—å¤åˆå‡½æ•°ä¸çœŸå® ReLU ä¹‹é—´çš„æœ€å¤§ç»å¯¹è¯¯å·® (L-infinity norm)ã€‚
    """
    num_coeffs_f1 = deg1 + 1
    # num_coeffs_f2 = deg2 + 1 # æœªç›´æ¥ä½¿ç”¨ï¼Œä½†ç”¨äºç†è§£
    
    coeffs_f1 = packed_coeffs[:num_coeffs_f1]
    coeffs_f2 = packed_coeffs[num_coeffs_f1:]

    y_predicted = f1_f2_composite(x_sample, coeffs_f1, coeffs_f2)
    
    max_abs_error = np.max(np.abs(y_predicted - y_true))
    return max_abs_error

def fit_single_relu_layer(model, relu_layer_name, args, global_save_dir):
    """
    å¯¹å•ä¸ª ReLU å±‚è¿›è¡Œ Minimax å¤åˆå¤šé¡¹å¼æ‹Ÿåˆï¼Œå¹¶ä¿å­˜ç»“æœã€‚
    """
    print(f"\n--- æ­£åœ¨å¤„ç† ReLU å±‚: '{relu_layer_name}' ---")
    
    # 1. è·å– ReLU è¾“å…¥æ•°æ®
    all_relu_inputs_flat, all_relu_inputs_tensor = get_relu_input_data_for_layer(
        model, relu_layer_name, args.batch_size, args.data_dir
    )
    
    if all_relu_inputs_flat is None:
        return {
            'status': 'skipped',
            'message': 'Failed to capture input data or layer not found.',
            'relu_layer_name': relu_layer_name
        }

    # ç¡®å®šæ‹Ÿåˆçš„è¾“å…¥èŒƒå›´ï¼šä»æ•°æ®ä¸­è§‚å¯Ÿåˆ°çš„æœ€å°å€¼åˆ°æœ€å¤§å€¼
    x_min = np.min(all_relu_inputs_flat)
    x_max = np.max(all_relu_inputs_flat)
    
    # åœ¨è¿™ä¸ªèŒƒå›´å†…å‡åŒ€é‡‡æ ·ç”¨äºæ‹Ÿåˆçš„ç‚¹
    x_range_for_fit = np.linspace(x_min, x_max, args.num_fit_points)
    y_true_for_fit = relu_true(x_range_for_fit)

    print(f"  ğŸ“Š æ‹ŸåˆèŒƒå›´ï¼š[{x_min:.4f}, {x_max:.4f}]")
    print(f"  ğŸ“ f1 å¤šé¡¹å¼é˜¶æ•° (d1)ï¼š{args.degree_f1}")
    print(f"  ğŸ“ f2 å¤šé¡¹å¼é˜¶æ•° (d2)ï¼š{args.degree_f2}")
    print(f"  ğŸ§ª å¤åˆå¤šé¡¹å¼ f1(f2(x)) ç†è®ºæœ€é«˜é˜¶æ•°ï¼š{args.degree_f1 * args.degree_f2}")
    print(f"  ğŸ§® æ‹Ÿåˆç‚¹æ•°é‡ï¼š{args.num_fit_points}")
    print(f"  ğŸ” ä¼˜åŒ–å™¨ï¼š{args.optimizer_method}")

    # æ£€æŸ¥å¤šé¡¹å¼é˜¶æ•°æ˜¯å¦åˆç†
    total_coeffs = (args.degree_f1 + 1) + (args.degree_f2 + 1)
    if total_coeffs > args.num_fit_points:
        print(f"âŒ é”™è¯¯ï¼šå¤šé¡¹å¼ç³»æ•°æ€»æ•° ({total_coeffs}) å¤§äºæ‹Ÿåˆç‚¹æ•°é‡ ({args.num_fit_points})ã€‚")
        print("  è¯·å¢åŠ  --num_fit_points æˆ–é™ä½å¤šé¡¹å¼é˜¶æ•°ã€‚è·³è¿‡æ­¤å±‚ã€‚")
        return {
            'status': 'failed',
            'message': 'Insufficient fit points for polynomial degrees.',
            'relu_layer_name': relu_layer_name,
            'degree_f1': args.degree_f1,
            'degree_f2': args.degree_f2,
            'x_min': float(x_min),
            'x_max': float(x_max)
        }

    # 2. åˆå§‹åŒ– f1 å’Œ f2 çš„ç³»æ•°
    # ä½¿ç”¨ç®€å•çš„çº¿æ€§æ‹Ÿåˆä½œä¸ºåˆå§‹çŒœæµ‹
    initial_coeffs_f2 = np.polyfit(x_range_for_fit, x_range_for_fit, args.degree_f2)
    initial_y_for_f1 = poly_eval(x_range_for_fit, initial_coeffs_f2)
    initial_coeffs_f1 = np.polyfit(initial_y_for_f1, y_true_for_fit, args.degree_f1)

    initial_packed_coeffs = np.concatenate((initial_coeffs_f1, initial_coeffs_f2))

    # print(f"  âœ¨ åˆå§‹æ‹Ÿåˆçš„æœ€å¤§ç»å¯¹è¯¯å·®ï¼š{objective_function(initial_packed_coeffs, x_range_for_fit, y_true_for_fit, args.degree_f1, args.degree_f2):.6f}")

    # 3. æ‰§è¡Œ Minimax ä¼˜åŒ–
    print(f"  ğŸš€ å¼€å§‹ Minimax æ‹Ÿåˆä¼˜åŒ– '{relu_layer_name}'...")
    result = minimize(
        objective_function,
        initial_packed_coeffs,
        args=(x_range_for_fit, y_true_for_fit, args.degree_f1, args.degree_f2),
        method=args.optimizer_method,
        options={'maxiter': args.max_iterations, 'disp': True} # disp=True æ‰“å°ä¼˜åŒ–è¿‡ç¨‹
    )

    if result.success:
        print(f"  ğŸ‰ ä¼˜åŒ–æˆåŠŸï¼")
        optimized_packed_coeffs = result.x
        final_max_error = result.fun
    else:
        print(f"  âŒ ä¼˜åŒ–å¤±è´¥æˆ–æœªæ”¶æ•›ï¼š{result.message}")
        optimized_packed_coeffs = initial_packed_coeffs # å¤±è´¥æ—¶ä½¿ç”¨åˆå§‹ç³»æ•°
        final_max_error = objective_function(initial_packed_coeffs, x_range_for_fit, y_true_for_fit, args.degree_f1, args.degree_f2)

    num_coeffs_f1 = args.degree_f1 + 1
    optimized_coeffs_f1 = optimized_packed_coeffs[:num_coeffs_f1]
    optimized_coeffs_f2 = optimized_packed_coeffs[num_coeffs_f1:]

    y_predicted_final = f1_f2_composite(x_range_for_fit, optimized_coeffs_f1, optimized_coeffs_f2)
    
    # è®¡ç®— MSE è¯¯å·®
    mse = np.mean((y_true_for_fit - y_predicted_final)**2)

    print(f"  ğŸ¯ æœ€ç»ˆæ‹Ÿåˆçš„æœ€å¤§ç»å¯¹è¯¯å·® (Minimax Error): {final_max_error:.6f}")
    print(f"  ğŸ“ˆ æœ€ç»ˆæ‹Ÿåˆçš„ MSE è¯¯å·®: {mse:.6f}")

    # 4. å¯è§†åŒ–ç»“æœ (é’ˆå¯¹æ¯ä¸ªé€šé“çš„åˆ†å¸ƒ)
    layer_save_dir = os.path.join(global_save_dir, relu_layer_name.replace(".", "_"))
    os.makedirs(layer_save_dir, exist_ok=True)

    # all_relu_inputs_tensor çš„å½¢çŠ¶: (N, C, H, W)
    # å±•å¹³ HxW ç»´åº¦ï¼Œä»¥ä¾¿æŒ‰é€šé“æŸ¥çœ‹åˆ†å¸ƒ (C, N*H*W)
    channel_data_for_plot = all_relu_inputs_tensor.permute(1, 0, 2, 3).reshape(all_relu_inputs_tensor.shape[1], -1).numpy()
    num_channels = channel_data_for_plot.shape[0]

    cols = int(np.ceil(np.sqrt(num_channels)))
    rows = int(np.ceil(num_channels / cols))

    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3))
    axes = axes.flatten() if num_channels > 1 else np.array([axes])

    for i in range(num_channels):
        ax = axes[i]
        ax.hist(channel_data_for_plot[i], bins=50, density=True, alpha=0.7, color='skyblue')
        # åœ¨æ¯ä¸ªé€šé“çš„ç›´æ–¹å›¾ä¸Šç»˜åˆ¶åŒä¸€æ¡æ‹Ÿåˆæ›²çº¿
        ax.plot(x_range_for_fit, y_predicted_final, color='red', linewidth=2, label=f'Composite Fit')
        ax.set_title(f'Channel {i+1}')
        ax.tick_params(axis='x', labelsize=8)
        ax.tick_params(axis='y', labelsize=8)
        ax.grid(True, linestyle='--', alpha=0.6)
        # if i == 0: ax.legend() # åªåœ¨ç¬¬ä¸€ä¸ªå­å›¾æ˜¾ç¤ºå›¾ä¾‹

    for i in range(num_channels, len(axes)):
        fig.delaxes(axes[i])

    plt.suptitle(f'ReLU Layer: {relu_layer_name}\nMinimax Composite Fit (d1={args.degree_f1}, d2={args.degree_f2})\nMax Abs Error: {final_max_error:.6f}, MSE: {mse:.6f}', fontsize=12)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    
    save_filename = os.path.join(layer_save_dir, f'{relu_layer_name.replace(".", "_")}_composite_fit_channels.jpg')
    plt.savefig(save_filename, dpi=200)
    plt.close(fig)
    print(f"  ğŸ–¼ï¸ æ‹Ÿåˆç»“æœå›¾å·²ä¿å­˜åˆ° {save_filename}")

    # 5. è¿”å›æ‹Ÿåˆç»“æœ
    return {
        'status': 'success' if result.success else 'failed',
        'message': result.message,
        'relu_layer_name': relu_layer_name,
        'degree_f1': args.degree_f1,
        'degree_f2': args.degree_f2,
        'f1_coeffs': optimized_coeffs_f1.tolist(),
        'f2_coeffs': optimized_coeffs_f2.tolist(),
        'x_min': float(x_min),
        'x_max': float(x_max),
        'final_max_error': float(final_max_error),
        'mse': float(mse),
        'optimization_success': bool(result.success)
    }


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Minimax fit ReLU function with a composite polynomial f1(f2(x)) for all ReLU layers.')

    parser.add_argument('--pth_file_path', type=str, 
                        default="/home/wangtianyu/relu_finetune/base_models/20_ckpt_92.23.pth",
                        help='Path to the .pth model file.')
    parser.add_argument('--batch_size', type=int, default=512,
                        help='Batch size for data loading.')
    parser.add_argument('--data_dir', type=str, default="./data",
                        help='Directory to store CIFAR-10 dataset.')
    parser.add_argument('--save_dir', type=str, 
                        default="/home/wangtianyu/relu_finetune/hook/minimax_composite_relu_all_layers",
                        help='Root directory to save fit plots and coefficients.')
    
    parser.add_argument('--degree_f1', type=int, default=31,
                        help='Degree of the first polynomial f1.')
    parser.add_argument('--degree_f2', type=int, default=31,
                        help='Degree of the second polynomial f2.')
    
    parser.add_argument('--num_fit_points', type=int, default=5000,
                        help='Number of uniformly sampled points in the range for fitting.')
    parser.add_argument('--optimizer_method', type=str, default='Nelder-Mead',
                        help='Optimization method for scipy.optimize.minimize. '
                             'Options: "Nelder-Mead", "Powell", "SLSQP", "L-BFGS-B" (try others if one fails).')
    parser.add_argument('--max_iterations', type=int, default=20000,
                        help='Maximum number of iterations for the optimizer.')


    args = parser.parse_args()

    # ç¡®ä¿ä¸»ä¿å­˜ç›®å½•å­˜åœ¨
    os.makedirs(args.save_dir, exist_ok=True)

    # 1. åŠ è½½æ¨¡å‹ (åªéœ€åŠ è½½ä¸€æ¬¡)
    model = resnet20()
    try:
        checkpoint = torch.load(args.pth_file_path, map_location=torch.device('cpu'))
        state_dict = checkpoint.get('net', checkpoint)
        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        model.load_state_dict(new_state_dict)
        print(f"âœ¨ æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡ï¼š{args.pth_file_path}")
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹æƒé‡å¤±è´¥ï¼š{e}")
        print("è¯·ç¡®ä¿ä½ çš„ .pth æ–‡ä»¶ä¸ ResNet20 æ¨¡å‹ç»“æ„åŒ¹é…ã€‚")
        exit()
    
    model.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    
    all_relu_fit_results = OrderedDict()
    
    # 2. éå†æ‰€æœ‰ ReLU å±‚å¹¶è¿›è¡Œæ‹Ÿåˆ
    relu_layer_names = []
    for name, module in model.named_modules():
        if isinstance(module, nn.ReLU):
            relu_layer_names.append(name)
    
    if not relu_layer_names:
        print("æœªåœ¨æ¨¡å‹ä¸­æ‰¾åˆ°ä»»ä½• nn.ReLU å±‚ã€‚")
        exit()

    print(f"\næ¨¡å‹ä¸­æ‰¾åˆ° {len(relu_layer_names)} ä¸ª ReLU å±‚ã€‚å¼€å§‹é€å±‚æ‹Ÿåˆ...")

    # æ¯æ¬¡å¾ªç¯ï¼Œéœ€è¦é‡æ–°æ³¨å†Œ Hookï¼Œå› ä¸º Hook ä¼šåœ¨æ•è·åå¤±æ•ˆæˆ–ç´¯ç§¯
    # å› æ­¤ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªå±‚åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„æ¨¡å‹å®ä¾‹æˆ–é‡æ–°åŠ è½½æ¨¡å‹ï¼Œä»¥ç¡®ä¿ Hook çš„ç‹¬ç«‹æ€§
    # æ›´é«˜æ•ˆçš„æ–¹æ³•æ˜¯ï¼Œåœ¨ get_relu_input_data_for_layer å†…éƒ¨æ³¨å†Œå¹¶ç§»é™¤ Hookï¼Œä½†PyTorch Hookç”Ÿå‘½å‘¨æœŸç®¡ç†å¤æ‚
    # æœ€ç®€å•çš„åšæ³•æ˜¯æ¯æ¬¡è·å–æ•°æ®æ—¶éƒ½é‡æ–°åŠ è½½æ¨¡å‹ï¼Œä»¥ç¡®ä¿æ¨¡å‹çŠ¶æ€å¹²å‡€
    
    # æ³¨æ„ï¼šä¸ºäº†é¿å…å¤šæ¬¡åŠ è½½æ¨¡å‹ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œä½¿ç”¨ä¸€ä¸ªâ€œclean_modelâ€çš„æ¦‚å¿µ
    # ä½†æ˜¯ hook æœºåˆ¶ä¼šéšç€ forward pass è§¦å‘ã€‚ä¸ºäº†ç¡®ä¿æ¯æ¬¡ hook æ•è·çš„æ˜¯å½“å‰å±‚çš„è¾“å…¥ï¼Œ
    # ä¸”ä¸è¢«ä¹‹å‰çš„ hook å¹²æ‰°ï¼Œéœ€è¦é‡æ–°æ„å»ºæ¨¡å‹æˆ–æ‰‹åŠ¨ç§»é™¤ hookã€‚
    # æœ€ç®€å•çš„åšæ³•æ˜¯è®© get_relu_input_data_for_layer å‡½æ•°åœ¨è·å–æ•°æ®åï¼Œ
    # ç§»é™¤å…¶æ³¨å†Œçš„ hookï¼Œä»¥é¿å…å¯¹åç»­å±‚çš„å½±å“ã€‚ä½† PyTorch é»˜è®¤ä¸ä¼šè‡ªåŠ¨ç§»é™¤ã€‚
    # å› æ­¤ï¼Œç›®å‰æœ€ç¨³å¦¥çš„æ–¹æ³•æ˜¯ï¼Œæ¯æ¬¡è°ƒç”¨ get_relu_input_data_for_layer æ—¶ï¼Œéƒ½é‡æ–°åŠ è½½ä¸€ä¸ªæ¨¡å‹å®ä¾‹
    # è¿™æ ·å¯ä»¥ç¡®ä¿æ¯ä¸ªhookéƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œä¸ä¼šäº’ç›¸å¹²æ‰°ã€‚ä½†ä¼šå¯¼è‡´åŠ è½½æ¨¡å‹å¤šæ¬¡ã€‚
    # è€ƒè™‘åˆ°æ•°æ®æ•è·åªåœ¨æ‹Ÿåˆå¼€å§‹æ—¶æ‰§è¡Œä¸€æ¬¡ï¼Œå…¶æ€§èƒ½å¼€é”€é€šå¸¸å°äºä¼˜åŒ–æœ¬èº«ã€‚
    
    # ä¿®æ”¹ï¼šget_relu_input_data_for_layer å°†æ¥æ”¶ pth_file_pathï¼Œå¹¶åœ¨å†…éƒ¨åŠ è½½æ¨¡å‹ä»¥ç¡®ä¿ç‹¬ç«‹æ€§
    # è¿™æ ·ï¼Œä¸»å¾ªç¯ä¸­çš„ model å®ä¾‹å¯ä»¥ä¿æŒä¸å˜ï¼Œç”¨äº named_modules éå†
    # è€Œæ¯ä¸ªæ‹Ÿåˆæ“ä½œçš„æ•°æ®æ•è·æ˜¯ç‹¬ç«‹çš„

    # å°† get_relu_input_data_for_layer çš„ model å‚æ•°æ”¹ä¸º pth_file_path
    # å¹¶è®©å®ƒåœ¨å†…éƒ¨åŠ è½½æ¨¡å‹
    def get_relu_input_data_for_layer_modified(pth_file_path, relu_layer_name, batch_size, data_dir):
        temp_model = resnet20()
        try:
            checkpoint = torch.load(pth_file_path, map_location=torch.device('cpu'))
            state_dict = checkpoint.get('net', checkpoint)
            new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
            temp_model.load_state_dict(new_state_dict)
            temp_model.eval()
        except Exception as e:
            print(f"âŒ ä¸´æ—¶æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
            return None, None

        # æ³¨å†Œ hook å¹¶è¿è¡Œæ•°æ®æ•è·
        relu_input_data_list = []
        hook_handle = None
        for name, module in temp_model.named_modules():
            if isinstance(module, nn.ReLU) and name == relu_layer_name:
                def hook_fn_local(module, input):
                    relu_input_data_list.append(input[0].detach().cpu())
                hook_handle = module.register_forward_pre_hook(hook_fn_local)
                break
        
        if hook_handle is None:
             print(f"âŒ æœªèƒ½ä¸º '{relu_layer_name}' æ³¨å†Œ Hookã€‚")
             return None, None

        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
        ])
        testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)
        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)

        with torch.no_grad():
            for i, (inputs, labels) in enumerate(testloader):
                _ = temp_model(inputs)
                # if i >= 10: break # é™åˆ¶æ‰¹æ¬¡ï¼ŒåŠ å¿«æ•°æ®æ•è·

        if hook_handle:
            hook_handle.remove() # ç§»é™¤ hook ä»¥é˜²æ­¢å¹²æ‰°

        if not relu_input_data_list:
            print(f"âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰æ•è·åˆ° '{relu_layer_name}' å±‚çš„è¾“å…¥ã€‚")
            return None, None

        all_relu_inputs_tensor = torch.cat(relu_input_data_list, dim=0)
        all_relu_inputs_flat = all_relu_inputs_tensor.numpy().flatten()
        
        return all_relu_inputs_flat, all_relu_inputs_tensor

    # æ›´æ–° fit_single_relu_layer å‡½æ•°çš„è°ƒç”¨ï¼Œä¼ é€’ pth_file_path
    def fit_single_relu_layer_updated(pth_file_path, relu_layer_name, args, global_save_dir):
        print(f"\n--- æ­£åœ¨å¤„ç† ReLU å±‚: '{relu_layer_name}' ---")
        
        # 1. è·å– ReLU è¾“å…¥æ•°æ®
        all_relu_inputs_flat, all_relu_inputs_tensor = get_relu_input_data_for_layer_modified(
            pth_file_path, relu_layer_name, args.batch_size, args.data_dir
        )
        
        if all_relu_inputs_flat is None:
            return {
                'status': 'skipped',
                'message': 'Failed to capture input data or layer not found.',
                'relu_layer_name': relu_layer_name
            }

        x_min = np.min(all_relu_inputs_flat)
        x_max = np.max(all_relu_inputs_flat)
        x_range_for_fit = np.linspace(x_min, x_max, args.num_fit_points)
        y_true_for_fit = relu_true(x_range_for_fit)

        print(f"  ğŸ“Š æ‹ŸåˆèŒƒå›´ï¼š[{x_min:.4f}, {x_max:.4f}]")
        print(f"  ğŸ“ f1 å¤šé¡¹å¼é˜¶æ•° (d1)ï¼š{args.degree_f1}")
        print(f"  ğŸ“ f2 å¤šé¡¹å¼é˜¶æ•° (d2)ï¼š{args.degree_f2}")
        print(f"  ğŸ§ª å¤åˆå¤šé¡¹å¼ f1(f2(x)) ç†è®ºæœ€é«˜é˜¶æ•°ï¼š{args.degree_f1 * args.degree_f2}")
        print(f"  ğŸ§® æ‹Ÿåˆç‚¹æ•°é‡ï¼š{args.num_fit_points}")
        print(f"  ğŸ” ä¼˜åŒ–å™¨ï¼š{args.optimizer_method}")

        total_coeffs = (args.degree_f1 + 1) + (args.degree_f2 + 1)
        if total_coeffs > args.num_fit_points:
            print(f"âŒ é”™è¯¯ï¼šå¤šé¡¹å¼ç³»æ•°æ€»æ•° ({total_coeffs}) å¤§äºæ‹Ÿåˆç‚¹æ•°é‡ ({args.num_fit_points})ã€‚")
            print("  è¯·å¢åŠ  --num_fit_points æˆ–é™ä½å¤šé¡¹å¼é˜¶æ•°ã€‚è·³è¿‡æ­¤å±‚ã€‚")
            return {
                'status': 'failed',
                'message': 'Insufficient fit points for polynomial degrees.',
                'relu_layer_name': relu_layer_name,
                'degree_f1': args.degree_f1,
                'degree_f2': args.degree_f2,
                'x_min': float(x_min),
                'x_max': float(x_max)
            }

        initial_coeffs_f2 = np.polyfit(x_range_for_fit, x_range_for_fit, args.degree_f2)
        initial_y_for_f1 = poly_eval(x_range_for_fit, initial_coeffs_f2)
        initial_coeffs_f1 = np.polyfit(initial_y_for_f1, y_true_for_fit, args.degree_f1)
        initial_packed_coeffs = np.concatenate((initial_coeffs_f1, initial_coeffs_f2))

        print(f"  ğŸš€ å¼€å§‹ Minimax æ‹Ÿåˆä¼˜åŒ– '{relu_layer_name}'...")
        result = minimize(
            objective_function,
            initial_packed_coeffs,
            args=(x_range_for_fit, y_true_for_fit, args.degree_f1, args.degree_f2),
            method=args.optimizer_method,
            options={'maxiter': args.max_iterations, 'disp': False} # disp=True æ‰“å°ä¼˜åŒ–è¿‡ç¨‹
        )

        if result.success:
            print(f"  ğŸ‰ ä¼˜åŒ–æˆåŠŸï¼")
            optimized_packed_coeffs = result.x
            final_max_error = result.fun
        else:
            print(f"  âŒ ä¼˜åŒ–å¤±è´¥æˆ–æœªæ”¶æ•›ï¼š{result.message}")
            optimized_packed_coeffs = initial_packed_coeffs
            final_max_error = objective_function(initial_packed_coeffs, x_range_for_fit, y_true_for_fit, args.degree_f1, args.degree_f2)

        num_coeffs_f1 = args.degree_f1 + 1
        optimized_coeffs_f1 = optimized_packed_coeffs[:num_coeffs_f1]
        optimized_coeffs_f2 = optimized_packed_coeffs[num_coeffs_f1:]

        y_predicted_final = f1_f2_composite(x_range_for_fit, optimized_coeffs_f1, optimized_coeffs_f2)
        mse = np.mean((y_true_for_fit - y_predicted_final)**2)

        print(f"  ğŸ¯ æœ€ç»ˆæ‹Ÿåˆçš„æœ€å¤§ç»å¯¹è¯¯å·® (Minimax Error): {final_max_error:.6f}")
        print(f"  ğŸ“ˆ æœ€ç»ˆæ‹Ÿåˆçš„ MSE è¯¯å·®: {mse:.6f}")

        layer_save_dir = os.path.join(global_save_dir, relu_layer_name.replace(".", "_"))
        os.makedirs(layer_save_dir, exist_ok=True)

        channel_data_for_plot = all_relu_inputs_tensor.permute(1, 0, 2, 3).reshape(all_relu_inputs_tensor.shape[1], -1).numpy()
        num_channels = channel_data_for_plot.shape[0]

        cols = int(np.ceil(np.sqrt(num_channels)))
        rows = int(np.ceil(num_channels / cols))

        fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3))
        axes = axes.flatten() if num_channels > 1 else np.array([axes])

        for i in range(num_channels):
            ax = axes[i]
            ax.hist(channel_data_for_plot[i], bins=50, density=True, alpha=0.7, color='skyblue')
            ax.plot(x_range_for_fit, y_predicted_final, color='red', linewidth=2, label=f'Composite Fit')
            ax.set_title(f'Channel {i+1}')
            ax.tick_params(axis='x', labelsize=8)
            ax.tick_params(axis='y', labelsize=8)
            ax.grid(True, linestyle='--', alpha=0.6)

        for i in range(num_channels, len(axes)):
            fig.delaxes(axes[i])

        plt.suptitle(f'ReLU Layer: {relu_layer_name}\nMinimax Composite Fit (d1={args.degree_f1}, d2={args.degree_f2})\nMax Abs Error: {final_max_error:.6f}, MSE: {mse:.6f}', fontsize=12)
        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        
        save_filename = os.path.join(layer_save_dir, f'{relu_layer_name.replace(".", "_")}_composite_fit_channels.jpg')
        plt.savefig(save_filename, dpi=200)
        plt.close(fig)
        print(f"  ğŸ–¼ï¸ æ‹Ÿåˆç»“æœå›¾å·²ä¿å­˜åˆ° {save_filename}")

        return {
            'status': 'success' if result.success else 'failed',
            'message': result.message,
            'relu_layer_name': relu_layer_name,
            'degree_f1': args.degree_f1,
            'degree_f2': args.degree_f2,
            'f1_coeffs': optimized_coeffs_f1.tolist(),
            'f2_coeffs': optimized_coeffs_f2.tolist(),
            'x_min': float(x_min),
            'x_max': float(x_max),
            'final_max_error': float(final_max_error),
            'mse': float(mse),
            'optimization_success': bool(result.success)
        }

    for relu_layer_name in relu_layer_names:
        result = fit_single_relu_layer_updated(args.pth_file_path, relu_layer_name, args, args.save_dir)
        all_relu_fit_results[relu_layer_name] = result

    # 3. ä¿å­˜æ‰€æœ‰æ‹Ÿåˆç»“æœåˆ° JSON
    coeffs_output_path = os.path.join(args.save_dir, 'all_relu_minimax_composite_coeffs.json')
    with open(coeffs_output_path, 'w') as f:
        json.dump(all_relu_fit_results, f, indent=4)
    print(f"\nğŸ’¾ æ‰€æœ‰ ReLU å±‚çš„æ‹Ÿåˆç³»æ•°å’Œä¿¡æ¯å·²ä¿å­˜åˆ° {coeffs_output_path}")

    print("\n--- Minimax å¤åˆæ‹Ÿåˆè„šæœ¬æ‰§è¡Œå®Œæ¯• ---")