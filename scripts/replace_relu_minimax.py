import torch
import torch.nn as nn
import numpy as np
import os
import argparse
import torchvision
import torchvision.transforms as transforms
from resnet import resnet20 # ç¡®ä¿ resnet.py åœ¨ä½ çš„è·¯å¾„ä¸­æˆ–å·²æ­£ç¡®å¯¼å…¥
import json
from collections import OrderedDict

# --- PyTorch å¤šé¡¹å¼æ±‚å€¼å‡½æ•° ---
def poly_eval_torch(x, coeffs):
    """
    ä½¿ç”¨ PyTorch æ“ä½œè®¡ç®—å¤šé¡¹å¼å€¼ (Horner æ³•åˆ™)ã€‚
    coeffs: torch.Tensor, é™å¹‚æ’åˆ— [c_n, c_{n-1}, ..., c_0]
    """
    if coeffs.numel() == 0: # Check if tensor is empty
        return torch.zeros_like(x)
    
    # Ensure coeffs are 1D
    coeffs = coeffs.flatten()

    result = coeffs[0] * x
    for i in range(1, coeffs.shape[0] - 1):
        result = result + coeffs[i]
        result = result * x
    result = result + coeffs[-1]
    return result

# --- è‡ªå®šä¹‰å¤åˆå¤šé¡¹å¼ ReLU æ¿€æ´»å‡½æ•°æ¨¡å— ---
class CompositePolynomialReLU(nn.Module):
    def __init__(self, relu_layer_name, f1_coeffs, f2_coeffs, x_min, x_max, original_relu_module=None):
        super(CompositePolynomialReLU, self).__init__()
        self.relu_layer_name = relu_layer_name
        
        # å°† NumPy æ•°ç»„è½¬æ¢ä¸º torch.Tensorï¼Œæ³¨å†Œä¸º buffer
        # buffer ä¸ä¼šè¢«è®­ç»ƒï¼Œä½†ä¼šéšæ¨¡å‹ç§»åŠ¨åˆ° GPU
        self.register_buffer('f1_coeffs', torch.tensor(f1_coeffs, dtype=torch.float32))
        self.register_buffer('f2_coeffs', torch.tensor(f2_coeffs, dtype=torch.float32))
        self.register_buffer('x_min', torch.tensor(x_min, dtype=torch.float32))
        self.register_buffer('x_max', torch.tensor(x_max, dtype=torch.float32))
        
        # å¼•ç”¨åŸå§‹ ReLU æ¨¡å—ï¼Œä»¥é˜²éœ€è¦å›é€€æˆ–è°ƒè¯•
        self.original_relu_module = original_relu_module 

    def forward(self, x):
        # å°†è¾“å…¥å€¼é™åˆ¶åœ¨æ‹ŸåˆèŒƒå›´å†…ï¼Œé˜²æ­¢å¤šé¡¹å¼å¤–æ¨äº§ç”Ÿçš„å¤§è¯¯å·®
        x_clipped = torch.clamp(x, self.x_min, self.x_max)

        # è®¡ç®— f2(x)
        y_intermediate = poly_eval_torch(x_clipped, self.f2_coeffs)

        # è®¡ç®— f1(f2(x))
        out = poly_eval_torch(y_intermediate, self.f1_coeffs)
        
        return out

# --- æ›¿æ¢ ReLU å‡½æ•°çš„é€’å½’è¾…åŠ©å‡½æ•° ---
def _replace_relu_recursive_helper(module, poly_coeffs_data, current_name_prefix=""):
    for name, child in module.named_children():
        # æ„å»ºå½“å‰ ReLU å±‚çš„å®Œæ•´è·¯å¾„å
        full_name = f"{current_name_prefix}.{name}" if current_name_prefix else name

        if isinstance(child, nn.ReLU):
            # æ£€æŸ¥å®Œæ•´è·¯å¾„åæ˜¯å¦åœ¨æ‹Ÿåˆæ•°æ®ä¸­ä¸”çŠ¶æ€ä¸ºæˆåŠŸ
            if full_name in poly_coeffs_data and poly_coeffs_data[full_name]['status'] == 'success':
                f1_coeffs_np = np.array(poly_coeffs_data[full_name]['f1_coeffs'], dtype=np.float32)
                f2_coeffs_np = np.array(poly_coeffs_data[full_name]['f2_coeffs'], dtype=np.float32)
                
                # è½¬æ¢ä¸º PyTorch Tensor
                f1_coeffs_tensor = torch.from_numpy(f1_coeffs_np)
                f2_coeffs_tensor = torch.from_numpy(f2_coeffs_np)
                
                x_min = poly_coeffs_data[full_name]['x_min']
                x_max = poly_coeffs_data[full_name]['x_max']
                
                new_relu_module = CompositePolynomialReLU(full_name, f1_coeffs_tensor, f2_coeffs_tensor, x_min, x_max, original_relu_module=child)
                # ä½¿ç”¨ setattr æ›¿æ¢æ¨¡å—
                setattr(module, name, new_relu_module)
                print(f"âœ… æˆåŠŸæ›¿æ¢å±‚ '{full_name}' ä¸º CompositePolynomialReLUã€‚")
            else:
                # æ‰“å°è­¦å‘Šæ—¶ä¹Ÿä½¿ç”¨å®Œæ•´çš„è·¯å¾„å
                print(f"âš ï¸ è­¦å‘Šï¼šå±‚ '{full_name}' çš„æ‹Ÿåˆæ•°æ®ç¼ºå¤±æˆ–æ‹Ÿåˆå¤±è´¥ï¼Œå°†ä¿ç•™åŸå§‹ nn.ReLUã€‚")
        elif len(list(child.children())) > 0: # å¦‚æœæ˜¯å®¹å™¨æ¨¡å—ï¼Œåˆ™é€’å½’è°ƒç”¨
            # é€’å½’è°ƒç”¨æ—¶ï¼Œä¼ é€’æ–°çš„å‰ç¼€
            _replace_relu_recursive_helper(child, poly_coeffs_data, full_name)
    return module

# --- ä¸»æ›¿æ¢å‡½æ•° ---
def replace_relu_with_composite_polynomial(model, poly_coeffs_data):
    # ä»æ ¹æ¨¡å—å¼€å§‹é€’å½’æ›¿æ¢
    return _replace_relu_recursive_helper(model, poly_coeffs_data)

# --- æµ‹è¯•æ¨¡å‹å‡†ç¡®ç‡çš„å‡½æ•° ---
def test_model_accuracy(model, batch_size, data_dir):
    """
    æµ‹è¯•ç»™å®šæ¨¡å‹çš„å‡†ç¡®ç‡ã€‚
    """
    model.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ])

    testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform_test)
    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)

    correct = 0
    total = 0
    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(testloader):
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    accuracy = 100. * correct / total
    return accuracy

# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Replace ReLU functions with composite polynomial approximations in ResNet20 and test accuracy.')

    parser.add_argument('--pth_file_path', type=str, 
                        default="/home/wangtianyu/relu_finetune/base_models/20_ckpt_92.23.pth",
                        help='Path to the .pth original model file.')
    parser.add_argument('--poly_coeffs_path', type=str, 
                        default="/home/wangtianyu/relu_finetune/hook/minimax_composite_relu_all_layers/all_relu_minimax_composite_coeffs.json",
                        help='Path to the JSON file containing all ReLU composite polynomial coefficients.')
    parser.add_argument('--batch_size', type=int, default=512,
                        help='Input batch size for data loading during accuracy test.')
    parser.add_argument('--data_dir', type=str, default="./data",
                        help='Directory to store CIFAR-10 dataset.')
    parser.add_argument('--output_model_path', type=str, default=None,
                        help='Optional: Path to save the modified model state_dict.')


    args = parser.parse_args()

    # 1. åŠ è½½æ‹Ÿåˆå¥½çš„å¤šé¡¹å¼ç³»æ•°
    if not os.path.exists(args.poly_coeffs_path):
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°å¤šé¡¹å¼ç³»æ•°æ–‡ä»¶ï¼š{args.poly_coeffs_path}")
        exit()
    
    with open(args.poly_coeffs_path, 'r') as f:
        poly_coeffs_data = json.load(f)
    print(f"âœ¨ æˆåŠŸåŠ è½½å¤šé¡¹å¼ç³»æ•°æ–‡ä»¶ï¼š{args.poly_coeffs_path}")

    # 2. åŠ è½½åŸå§‹æ¨¡å‹å’Œæƒé‡
    original_model = resnet20()
    try:
        checkpoint = torch.load(args.pth_file_path, map_location=torch.device('cpu'))
        state_dict = checkpoint.get('net', checkpoint)
        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        original_model.load_state_dict(new_state_dict)
        print(f"âœ¨ æˆåŠŸåŠ è½½åŸå§‹æ¨¡å‹æƒé‡ï¼š{args.pth_file_path}")
    except Exception as e:
        print(f"âŒ åŠ è½½åŸå§‹æ¨¡å‹æƒé‡å¤±è´¥ï¼š{e}")
        print("è¯·ç¡®ä¿ä½ çš„ .pth æ–‡ä»¶ä¸ ResNet20 æ¨¡å‹ç»“æ„åŒ¹é…ã€‚")
        exit()

    # 3. æ›¿æ¢æ¨¡å‹ä¸­çš„ ReLU å‡½æ•°
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å¯¹åŸå§‹æ¨¡å‹çš„å‰¯æœ¬è¿›è¡Œæ›¿æ¢ï¼Œä»¥ä¿ç•™åŸå§‹æ¨¡å‹
    modified_model = replace_relu_with_composite_polynomial(original_model, poly_coeffs_data)
    
    # 4. æµ‹è¯•ä¿®æ”¹åæ¨¡å‹çš„å‡†ç¡®ç‡
    print("\nğŸš€ å¼€å§‹æµ‹è¯•æ›¿æ¢ ReLU åçš„æ¨¡å‹å‡†ç¡®ç‡...")
    accuracy = test_model_accuracy(modified_model, args.batch_size, args.data_dir)
    print(f"\nâœ… æ›¿æ¢ ReLU ä¸ºå¤åˆå¤šé¡¹å¼åï¼Œæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡: {accuracy:.2f}%")

    # 5. å¯é€‰ï¼šä¿å­˜ä¿®æ”¹åçš„æ¨¡å‹æƒé‡
    if args.output_model_path:
        os.makedirs(os.path.dirname(args.output_model_path) or '.', exist_ok=True)
        torch.save(modified_model.state_dict(), args.output_model_path)
        print(f"ğŸ’¾ ä¿®æ”¹åçš„æ¨¡å‹æƒé‡å·²ä¿å­˜åˆ°ï¼š{args.output_model_path}")

    print("\n--- æ›¿æ¢ ReLU è„šæœ¬æ‰§è¡Œå®Œæ¯• ---")